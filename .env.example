# API Keys (Optional - can use free local embeddings instead)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Pipeline Configuration
CHUNK_SIZE=800                 # Size of text chunks (enforced for all document types)
CHUNK_OVERLAP=120              # Overlap between chunks (in tokens)
BATCH_SIZE=10                  # Batch size for embedding generation

# Document Processing
# Uncomment to set custom spaCy model (improves chunking quality)
# SPACY_MODEL=en_core_web_md   # Default spaCy model for NLP-based chunking
# Note: Install with: pip install spacy && python -m spacy download en_core_web_md

# Embedding Model Selection
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2  # Default model (FREE - no API key required)
# Other model options:
# EMBEDDING_MODEL=text-embedding-3-small  # OpenAI model (requires API key)
# EMBEDDING_MODEL=BAAI/bge-m3  # Free alternative
# EMBEDDING_MODEL=Snowflake/snowflake-arctic-embed-m  # Free alternative

# File Handling
SUPPORTED_EXTENSIONS=.md,.txt,.pdf,.docx,.doc  # Comma-separated list of supported file extensions

# Server Configuration
CLAUDE_MODEL=claude-3-7-sonnet-20240307  # Claude model to use
MAX_RESULTS=10                 # Maximum number of results to return
USE_ANTHROPIC=true             # Whether to use Anthropic API for responses